# bistro

Opinionated GPT implementation and finetuning harness.

Tip: Pass `--dtype bfloat16` when using `convert_hf_checkpoint`, will speed up loading the model 2-3x.

Tip: Install Flash Attention 2 using the intructions [here](https://github.com/Dao-AILab/flash-attention) for a speedup.

## Acknowledgements

Built on [lit-gpt](https://github.com/Lightning-AI/lit-gpt).
